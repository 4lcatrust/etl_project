[2025-03-09T10:17:04.301+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:17:04.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:17:04.304+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:17:04.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:17:04.778+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:17:04.776+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T10:17:04.779+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:17:04.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.498 seconds
[2025-03-09T10:17:35.630+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:17:35.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:17:35.633+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:17:35.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:17:35.848+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:17:35.847+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T10:17:35.849+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:17:35.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.227 seconds
[2025-03-09T10:18:07.973+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:18:07.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:18:07.977+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:18:07.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:18:09.721+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:18:09.684+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T10:18:09.723+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:18:09.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.777 seconds
[2025-03-09T10:18:39.840+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:18:39.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:18:39.844+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:18:39.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:18:40.254+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:18:40.253+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T10:18:40.254+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:18:40.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.435 seconds
[2025-03-09T10:19:10.310+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:19:10.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:19:10.312+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:19:10.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:19:10.667+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:19:10.666+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T10:19:10.668+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:19:10.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.368 seconds
[2025-03-09T10:19:41.729+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:19:41.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:19:41.733+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:19:41.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:19:42.081+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:19:42.080+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T10:19:42.082+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:19:42.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.368 seconds
[2025-03-09T10:20:13.142+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:20:13.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:20:13.145+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:20:13.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:20:13.473+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:20:13.472+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T10:20:13.473+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:20:13.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.358 seconds
[2025-03-09T10:20:44.562+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:20:44.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:20:44.564+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:20:44.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:20:44.752+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:20:44.750+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T10:20:44.752+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:20:44.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.198 seconds
[2025-03-09T10:29:09.437+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:29:09.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:29:09.440+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:29:09.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:29:10.393+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:29:10.393+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff90d10560>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T10:29:10.393+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:29:10.393+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T10:29:10.397+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:29:10.393+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff7a8be0f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a8be0f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a8be0f0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T10:29:10.398+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:29:10.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.971 seconds
[2025-03-09T10:29:41.395+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:29:41.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:29:41.398+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:29:41.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:29:41.667+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:29:41.666+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a14f560>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T10:29:41.667+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:29:41.667+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T10:29:41.671+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:29:41.667+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff7a78fe90>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a78fe90>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a78fe90>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T10:29:41.672+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:29:41.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.293 seconds
[2025-03-09T10:30:11.753+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:30:11.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:30:11.756+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:30:11.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:30:12.148+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:30:12.148+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff90dd5670>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T10:30:12.149+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:30:12.149+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T10:30:12.151+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:30:12.149+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff90d57e90>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff90d57e90>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff90d57e90>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T10:30:12.152+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:30:12.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.409 seconds
[2025-03-09T10:30:43.198+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:30:43.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:30:43.200+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:30:43.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:30:43.583+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:30:43.583+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff79bdcda0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T10:30:43.584+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:30:43.584+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T10:30:43.587+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:30:43.584+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff7a091970>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a091970>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a091970>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T10:30:43.588+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:30:43.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.398 seconds
[2025-03-09T10:31:14.599+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:31:14.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T10:31:14.601+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:31:14.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:31:14.947+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:31:14.947+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff90c0baa0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T10:31:14.947+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:31:14.947+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T10:31:14.950+0000] {logging_mixin.py:190} INFO - [2025-03-09T10:31:14.947+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff969860f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff969860f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff969860f0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T10:31:14.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T10:31:14.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.359 seconds
[2025-03-09T11:05:19.494+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T11:05:19.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T11:05:19.497+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:05:19.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T11:05:20.707+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:05:20.706+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7076f020>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T11:05:20.708+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:05:20.708+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T11:05:20.751+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:05:20.708+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff702a24e0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff702a24e0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff702a24e0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T11:05:20.757+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T11:05:20.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.300 seconds
[2025-03-09T11:06:22.877+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T11:06:22.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T11:06:22.880+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:06:22.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T11:06:23.742+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:06:23.742+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8f997fe0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T11:06:23.742+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:06:23.742+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T11:06:23.746+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:06:23.743+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff8f9eaba0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8f9eaba0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8f9eaba0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T11:06:23.747+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T11:06:23.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.880 seconds
[2025-03-09T11:06:53.846+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T11:06:53.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T11:06:53.847+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:06:53.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T11:06:54.155+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:06:54.154+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffabc3e5a0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T11:06:54.155+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:06:54.155+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T11:06:54.159+0000] {logging_mixin.py:190} INFO - [2025-03-09T11:06:54.155+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff9023fa70>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff9023fa70>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff9023fa70>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T11:06:54.160+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T11:06:54.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.323 seconds
[2025-03-09T13:09:24.412+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:09:24.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:09:24.414+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:09:24.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:09:24.675+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:09:24.675+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa1cd8560>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:09:24.676+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:09:24.676+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:09:24.681+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:09:24.676+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff8c1cde50>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8c1cde50>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8c1cde50>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:09:24.682+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:09:24.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.276 seconds
[2025-03-09T13:09:55.445+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:09:55.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:09:55.447+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:09:55.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:09:55.694+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:09:55.694+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8c12f500>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:09:55.695+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:09:55.695+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:09:55.701+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:09:55.695+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff8c1ca2a0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8c1ca2a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8c1ca2a0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:09:55.701+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:09:55.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.265 seconds
[2025-03-09T13:11:39.820+0000] {processor.py:186} INFO - Started process (PID=24) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:11:39.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:11:39.823+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:11:39.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:11:41.046+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:11:41.046+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6f77a540>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:11:41.047+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:11:41.047+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:11:41.051+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:11:41.047+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff78e8e0f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff78e8e0f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff78e8e0f0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:11:41.053+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:11:41.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.244 seconds
[2025-03-09T13:12:11.900+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:12:11.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:12:11.905+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:12:11.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:12:12.166+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:12:12.166+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a3c9a90>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:12:12.167+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:12:12.167+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:12:12.172+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:12:12.167+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff7a3ffa10>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a3ffa10>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7a3ffa10>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:12:12.173+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:12:12.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.285 seconds
[2025-03-09T13:18:43.253+0000] {processor.py:186} INFO - Started process (PID=24) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:18:43.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:18:43.258+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:18:43.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:18:44.162+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:18:44.161+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff957a7590>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:18:44.162+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:18:44.162+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:18:44.166+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:18:44.162+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff95629880>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff95629880>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff95629880>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:18:44.167+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:18:44.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.921 seconds
[2025-03-09T13:19:14.213+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:19:14.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:19:14.215+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:19:14.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:19:14.515+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:19:14.515+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff99927020>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:19:14.516+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:19:14.516+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:19:14.520+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:19:14.516+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff94dbe7e0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff94dbe7e0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff94dbe7e0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:19:14.521+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:19:14.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.320 seconds
[2025-03-09T13:19:45.340+0000] {processor.py:186} INFO - Started process (PID=38) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:19:45.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:19:45.343+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:19:45.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:19:45.646+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:19:45.646+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff9991d2b0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:19:45.647+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:19:45.647+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:19:45.652+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:19:45.647+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff94ce5490>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff94ce5490>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff94ce5490>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:19:45.654+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:19:45.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.325 seconds
[2025-03-09T13:20:21.471+0000] {processor.py:186} INFO - Started process (PID=24) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:20:21.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:20:21.473+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:20:21.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:20:22.595+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:20:22.595+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff926df050>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:20:22.595+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:20:22.595+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:20:22.599+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:20:22.595+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffffa8b524e0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa8b524e0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa8b524e0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:20:22.600+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:20:22.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.138 seconds
[2025-03-09T13:20:42.496+0000] {processor.py:186} INFO - Started process (PID=24) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:20:42.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:20:42.497+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:20:42.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:20:43.256+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:20:43.255+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff60e47f80>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:20:43.256+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:20:43.256+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:20:43.263+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:20:43.256+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff614bf230>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff614bf230>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff614bf230>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:20:43.264+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:20:43.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.777 seconds
[2025-03-09T13:23:36.102+0000] {processor.py:186} INFO - Started process (PID=22) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:23:36.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:23:36.105+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:23:36.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:23:36.147+0000] {processor.py:186} INFO - Started process (PID=22) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:23:36.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:23:36.151+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:23:36.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:23:37.181+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:23:37.179+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T13:23:37.182+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:23:37.179+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T13:23:37.182+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:23:37.183+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:23:37.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.092 seconds
[2025-03-09T13:23:37.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.050 seconds
[2025-03-09T13:24:07.289+0000] {processor.py:186} INFO - Started process (PID=29) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:07.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:24:07.294+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:07.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:07.315+0000] {processor.py:186} INFO - Started process (PID=29) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:07.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:24:07.325+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:07.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:07.742+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:07.742+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffae2f7830>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:24:07.743+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:07.743+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:24:07.745+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:07.743+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff79cae570>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:24:07.745+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:07.745+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:24:07.749+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:07.743+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff97565490>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff97565490>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff97565490>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:24:07.750+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:07.752+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:07.746+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff95a17ec0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff95a17ec0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff95a17ec0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:24:07.754+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:07.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.477 seconds
[2025-03-09T13:24:07.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.456 seconds
[2025-03-09T13:24:38.552+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:38.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:24:38.556+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:38.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:38.599+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:38.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:24:38.601+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:38.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:38.865+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:38.865+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff97bce510>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:24:38.866+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:38.865+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:24:38.872+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:38.866+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff97f0f3e0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff97f0f3e0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff97f0f3e0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:24:38.873+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:38.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.330 seconds
[2025-03-09T13:24:38.889+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:38.889+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7d9d3080>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:24:38.889+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:38.889+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:24:38.892+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:24:38.889+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff791d16d0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff791d16d0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff791d16d0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:24:38.893+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:24:38.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.302 seconds
[2025-03-09T13:25:09.670+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:09.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:25:09.673+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:09.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:09.693+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:09.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:25:09.697+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:09.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:10.337+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:10.337+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff983eaba0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:25:10.338+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:10.338+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:25:10.346+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:10.338+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffffb54637d0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffb54637d0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffb54637d0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:25:10.348+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:10.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.699 seconds
[2025-03-09T13:25:10.371+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:10.370+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8cd8b4d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:25:10.371+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:10.371+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:25:10.374+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:10.371+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff96a58aa0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff96a58aa0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff96a58aa0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:25:10.376+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:10.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.691 seconds
[2025-03-09T13:25:40.865+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:40.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:25:40.871+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:40.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:40.877+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:40.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:25:40.882+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:40.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:41.523+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:41.523+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffae309700>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:25:41.524+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:41.524+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff791f6e70>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:25:41.526+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:41.525+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:25:41.525+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:41.525+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:25:41.532+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:41.528+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff9856bf80>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff9856bf80>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff9856bf80>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:25:41.535+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:41.535+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:25:41.526+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff8cd68aa0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8cd68aa0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8cd68aa0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:25:41.537+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:25:41.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.673 seconds
[2025-03-09T13:25:41.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.694 seconds
[2025-03-09T13:26:10.048+0000] {processor.py:186} INFO - Started process (PID=22) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:26:10.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:26:10.051+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:26:10.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:26:11.165+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:26:11.163+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T13:26:11.166+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:26:11.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.132 seconds
[2025-03-09T13:27:34.499+0000] {processor.py:186} INFO - Started process (PID=22) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:27:34.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:27:34.501+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:27:34.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:27:35.516+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:27:35.515+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T13:27:35.517+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:27:35.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.026 seconds
[2025-03-09T13:28:06.529+0000] {processor.py:186} INFO - Started process (PID=29) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:28:06.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:28:06.531+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:28:06.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:28:06.786+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:28:06.786+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa7ef9eb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:28:06.787+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:28:06.787+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:28:06.791+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:28:06.787+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffffa7f2dd60>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa7f2dd60>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa7f2dd60>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:28:06.792+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:28:06.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.272 seconds
[2025-03-09T13:28:36.823+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:28:36.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:28:36.825+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:28:36.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:28:37.126+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:28:37.126+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa83a9a60>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:28:37.129+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:28:37.128+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:28:37.133+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:28:37.130+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff91f906b0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff91f906b0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff91f906b0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:28:37.134+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:28:37.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.320 seconds
[2025-03-09T13:29:08.194+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:29:08.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:29:08.196+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:29:08.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:29:08.582+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:29:08.582+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff91bbe570>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:29:08.583+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:29:08.583+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:29:08.586+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:29:08.583+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff91006ea0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff91006ea0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff91006ea0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:29:08.587+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:29:08.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.400 seconds
[2025-03-09T13:29:39.614+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:29:39.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:29:39.616+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:29:39.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:29:39.975+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:29:39.974+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff917c6930>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:29:39.975+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:29:39.975+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:29:39.978+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:29:39.975+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffffa710f2f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa710f2f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa710f2f0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:29:39.980+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:29:39.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.376 seconds
[2025-03-09T13:30:11.007+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:30:11.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:30:11.009+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:30:11.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:30:11.410+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:30:11.409+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa83c30b0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:30:11.410+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:30:11.410+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:30:11.413+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:30:11.410+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffffa837b620>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa837b620>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa837b620>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:30:11.414+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:30:11.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.416 seconds
[2025-03-09T13:30:55.702+0000] {processor.py:186} INFO - Started process (PID=22) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:30:55.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:30:55.715+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:30:55.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:30:57.047+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:30:57.044+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T13:30:57.049+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:30:57.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.362 seconds
[2025-03-09T13:31:27.123+0000] {processor.py:186} INFO - Started process (PID=29) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:31:27.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:31:27.125+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:31:27.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:31:27.532+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:31:27.532+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffafa12750>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:31:27.533+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:31:27.533+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:31:27.538+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:31:27.533+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffffa944efc0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa944efc0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa944efc0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:31:27.539+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:31:27.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.424 seconds
[2025-03-09T13:31:58.642+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:31:58.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:31:58.644+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:31:58.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:31:58.879+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:31:58.879+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff922596a0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:31:58.880+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:31:58.879+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:31:58.883+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:31:58.880+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff928f4110>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff928f4110>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff928f4110>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:31:58.884+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:31:58.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.249 seconds
[2025-03-09T13:32:29.983+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:32:29.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:32:29.985+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:32:29.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:32:30.409+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:32:30.409+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffaffc3590>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:32:30.409+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:32:30.409+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:32:30.412+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:32:30.409+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff928f4110>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff928f4110>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff928f4110>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:32:30.413+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:32:30.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.453 seconds
[2025-03-09T13:33:01.150+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:33:01.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:33:01.154+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:33:01.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:33:01.650+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:33:01.650+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff96e544a0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:33:01.650+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:33:01.650+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:33:01.653+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:33:01.650+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff9284b4d0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff9284b4d0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff9284b4d0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:33:01.654+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:33:01.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.511 seconds
[2025-03-09T13:33:32.725+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:33:32.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:33:32.730+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:33:32.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:33:33.114+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:33:33.113+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff930e6270>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:33:33.114+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:33:33.114+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:33:33.117+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:33:33.114+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffffa2583500>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa2583500>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa2583500>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:33:33.118+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:33:33.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.407 seconds
[2025-03-09T13:34:03.852+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:34:03.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:34:03.853+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:34:03.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:34:04.307+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:34:04.307+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff930043e0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:34:04.308+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:34:04.308+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:34:04.311+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:34:04.308+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff928ba060>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff928ba060>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff928ba060>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:34:04.312+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:34:04.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.469 seconds
[2025-03-09T13:34:35.496+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:34:35.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:34:35.499+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:34:35.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:34:35.900+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:34:35.900+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff92eac440>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:34:35.900+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:34:35.900+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:34:35.903+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:34:35.900+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffffa2583620>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa2583620>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa2583620>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:34:35.904+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:34:35.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.433 seconds
[2025-03-09T13:35:06.963+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:35:06.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:35:06.966+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:35:06.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:35:07.200+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:35:07.200+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffb01a9970>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:35:07.201+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:35:07.201+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:35:07.204+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:35:07.201+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff96e2a5a0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff96e2a5a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff96e2a5a0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:35:07.205+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:35:07.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.250 seconds
[2025-03-09T13:35:38.270+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:35:38.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:35:38.273+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:35:38.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:35:38.552+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:35:38.552+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff928d1430>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:35:38.552+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:35:38.552+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:35:38.556+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:35:38.553+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff92287e90>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff92287e90>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff92287e90>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:35:38.556+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:35:38.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.302 seconds
[2025-03-09T13:36:09.406+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:36:09.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:36:09.408+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:36:09.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:36:09.786+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:36:09.786+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff92992150>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:36:09.787+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:36:09.786+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:36:09.789+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:36:09.787+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff928d4110>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff928d4110>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff928d4110>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:36:09.790+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:36:09.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.392 seconds
[2025-03-09T13:36:40.566+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:36:40.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:36:40.568+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:36:40.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:36:40.945+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:36:40.945+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff971d73e0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:36:40.945+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:36:40.945+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:36:40.948+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:36:40.946+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff9296efc0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff9296efc0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff9296efc0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:36:40.949+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:36:40.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.390 seconds
[2025-03-09T13:37:11.766+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:37:11.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:37:11.768+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:37:11.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:37:12.201+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:37:12.201+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa633af00>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:37:12.202+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:37:12.202+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:37:12.206+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:37:12.202+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffffa95c3a70>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa95c3a70>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffffa95c3a70>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:37:12.207+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:37:12.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.460 seconds
[2025-03-09T13:37:42.938+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:37:42.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:37:42.940+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:37:42.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:37:43.312+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:37:43.312+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff971d0590>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:37:43.313+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:37:43.313+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:37:43.316+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:37:43.313+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff92f860f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff92f860f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff92f860f0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:37:43.316+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:37:43.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.396 seconds
[2025-03-09T13:38:25.571+0000] {processor.py:186} INFO - Started process (PID=21) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:38:25.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:38:25.578+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:38:25.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:38:26.816+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:38:26.814+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T13:38:26.817+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:38:26.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.256 seconds
[2025-03-09T13:38:56.979+0000] {processor.py:186} INFO - Started process (PID=28) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:38:56.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:38:56.982+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:38:56.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:38:57.280+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:38:57.280+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6b4fbbf0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:38:57.280+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:38:57.280+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:38:57.287+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:38:57.280+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff6ad2a090>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6ad2a090>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6ad2a090>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:38:57.288+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:38:57.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.316 seconds
[2025-03-09T13:39:28.060+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:39:28.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:39:28.061+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:39:28.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:39:28.293+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:39:28.293+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6ad32600>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:39:28.293+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:39:28.293+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:39:28.296+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:39:28.293+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff6add8ad0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6add8ad0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6add8ad0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:39:28.297+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:39:28.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.246 seconds
[2025-03-09T13:39:59.417+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:39:59.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:39:59.419+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:39:59.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:39:59.946+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:39:59.946+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6ade9340>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:39:59.947+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:39:59.947+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:39:59.964+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:39:59.947+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff6adc4a10>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6adc4a10>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6adc4a10>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:39:59.965+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:39:59.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.565 seconds
[2025-03-09T13:40:30.071+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:40:30.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:40:30.073+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:40:30.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:40:30.447+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:40:30.447+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6f5b1e80>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:40:30.448+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:40:30.448+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:40:30.451+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:40:30.448+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff815066f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff815066f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff815066f0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:40:30.452+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:40:30.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.388 seconds
[2025-03-09T13:41:01.256+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:41:01.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:41:01.258+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:41:01.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:41:01.674+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:41:01.674+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff8196fb00>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:41:01.674+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:41:01.674+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:41:01.677+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:41:01.674+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff6b550fb0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6b550fb0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6b550fb0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:41:01.678+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:41:01.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.429 seconds
[2025-03-09T13:41:32.366+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:41:32.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:41:32.368+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:41:32.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:41:32.774+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:41:32.774+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6a67f260>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:41:32.775+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:41:32.775+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:41:32.778+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:41:32.775+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff87617b00>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff87617b00>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff87617b00>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:41:32.779+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:41:32.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.420 seconds
[2025-03-09T13:42:04.172+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:42:04.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:42:04.176+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:04.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:42:04.560+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:04.559+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6ac07860>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T13:42:04.560+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:04.560+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T13:42:04.563+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:04.560+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff6acbcce0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6acbcce0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 77, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='127.0.0.1', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff6acbcce0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://127.0.0.1:8123)
[2025-03-09T13:42:04.564+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:42:04.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.403 seconds
[2025-03-09T13:42:18.461+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:42:18.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:42:18.466+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:18.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:42:19.034+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:42:19.091+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.091+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T13:42:19.095+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.094+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T13:42:19.096+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.096+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T13:42:19.098+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.098+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:42:19.100+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.100+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:42:19.102+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.102+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:42:19.103+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.103+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:42:19.103+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:42:19.109+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.109+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:42:19.113+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:19.113+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:42:19.115+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'default_view': 'grid', 'schedule_interval': Duration(days=1), 'next_dagrun_data_interval_end': DateTime(2025, 3, 9, 0, 0, 0, tzinfo=Timezone('UTC') ... (839 characters truncated) ... _name': None, 'root_dag_id': None, 'scheduler_lock': None, 'pickle_id': None, 'dataset_expression': None, 'last_expired': None, 'last_pickled': None}]]
[2025-03-09T13:42:49.547+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:42:49.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:42:49.566+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:49.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:42:49.881+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:42:49.902+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:49.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:42:49.913+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:49.913+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:42:49.919+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:42:49.918+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:42:49.922+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'default_view': 'grid', 'schedule_interval': Duration(days=1), 'next_dagrun_data_interval_end': DateTime(2025, 3, 9, 0, 0, 0, tzinfo=Timezone('UTC') ... (839 characters truncated) ... _name': None, 'root_dag_id': None, 'scheduler_lock': None, 'pickle_id': None, 'dataset_expression': None, 'last_expired': None, 'last_pickled': None}]]
[2025-03-09T13:44:49.615+0000] {processor.py:186} INFO - Started process (PID=15) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:44:49.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:44:49.625+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:44:49.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:44:51.581+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:44:51.574+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T13:44:51.586+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:44:51.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.996 seconds
[2025-03-09T13:45:22.045+0000] {processor.py:186} INFO - Started process (PID=26) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:45:22.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:45:22.051+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:45:22.535+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:45:22.666+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.666+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T13:45:22.680+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.680+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T13:45:22.684+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.684+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T13:45:22.686+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.686+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:45:22.688+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.688+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:45:22.691+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.691+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:45:22.693+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.692+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:45:22.694+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:45:22.704+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.704+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:45:22.710+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:22.710+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:45:22.713+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'has_import_errors': False, 'fileloc': '/opt/airflow/dags/dag_daily_transaction_summary.py', 'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Tim ... (839 characters truncated) ... _name': None, 'scheduler_lock': None, 'pickle_id': None, 'dataset_expression': None, 'last_expired': None, 'root_dag_id': None, 'last_pickled': None}]]
[2025-03-09T13:45:53.269+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:45:53.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:45:53.275+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:53.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:45:53.594+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:45:53.605+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:53.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:45:53.612+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:53.612+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:45:53.623+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:45:53.623+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:45:53.630+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'has_import_errors': False, 'fileloc': '/opt/airflow/dags/dag_daily_transaction_summary.py', 'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Tim ... (839 characters truncated) ... _name': None, 'scheduler_lock': None, 'pickle_id': None, 'dataset_expression': None, 'last_expired': None, 'root_dag_id': None, 'last_pickled': None}]]
[2025-03-09T13:46:24.342+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:46:24.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:46:24.349+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:46:24.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:46:24.827+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:46:24.836+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:46:24.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:46:24.843+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:46:24.843+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:46:24.849+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:46:24.849+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:46:24.852+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'has_import_errors': False, 'fileloc': '/opt/airflow/dags/dag_daily_transaction_summary.py', 'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Tim ... (839 characters truncated) ... _name': None, 'scheduler_lock': None, 'pickle_id': None, 'dataset_expression': None, 'last_expired': None, 'root_dag_id': None, 'last_pickled': None}]]
[2025-03-09T13:46:55.521+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:46:55.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:46:55.529+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:46:55.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:46:56.135+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:46:56.145+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:46:56.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:46:56.153+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:46:56.152+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:46:56.158+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:46:56.158+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:46:56.160+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'has_import_errors': False, 'fileloc': '/opt/airflow/dags/dag_daily_transaction_summary.py', 'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Tim ... (839 characters truncated) ... _name': None, 'scheduler_lock': None, 'pickle_id': None, 'dataset_expression': None, 'last_expired': None, 'root_dag_id': None, 'last_pickled': None}]]
[2025-03-09T13:47:26.908+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:47:26.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:47:26.912+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:47:26.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:47:27.390+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:47:27.398+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:47:27.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:47:27.404+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:47:27.404+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:47:27.408+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:47:27.408+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:47:27.411+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'has_import_errors': False, 'fileloc': '/opt/airflow/dags/dag_daily_transaction_summary.py', 'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Tim ... (839 characters truncated) ... _name': None, 'scheduler_lock': None, 'pickle_id': None, 'dataset_expression': None, 'last_expired': None, 'root_dag_id': None, 'last_pickled': None}]]
[2025-03-09T13:48:16.758+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:48:16.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:48:16.762+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:16.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:48:18.430+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:18.425+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 71, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T13:48:18.431+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:48:18.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.696 seconds
[2025-03-09T13:48:48.966+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:48:48.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:48:48.972+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:48.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:48:49.433+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:48:49.548+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.548+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T13:48:49.556+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.556+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T13:48:49.566+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.566+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T13:48:49.572+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.572+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:48:49.576+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.576+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:48:49.579+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.579+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:48:49.581+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.581+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:48:49.581+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:48:49.587+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.587+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:48:49.592+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:48:49.592+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:48:49.595+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'owners': 'airflow', 'last_parsed_time': datetime.datetime(2025, 3, 9, 13, 48, 49, 591698, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflo ... (839 characters truncated) ... d': None, 'dag_display_name': None, 'root_dag_id': None, 'scheduler_lock': None, 'dataset_expression': None, 'last_expired': None, 'pickle_id': None}]]
[2025-03-09T13:49:20.255+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:49:20.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:49:20.261+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:49:20.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:49:20.616+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:49:20.629+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:49:20.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:49:20.642+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:49:20.641+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:49:20.660+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:49:20.659+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:49:20.664+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'owners': 'airflow', 'last_parsed_time': datetime.datetime(2025, 3, 9, 13, 49, 20, 658243, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflo ... (839 characters truncated) ... d': None, 'dag_display_name': None, 'root_dag_id': None, 'scheduler_lock': None, 'dataset_expression': None, 'last_expired': None, 'pickle_id': None}]]
[2025-03-09T13:49:51.399+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:49:51.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:49:51.402+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:49:51.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:49:51.944+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:49:51.965+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:49:51.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:49:51.975+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:49:51.975+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:49:51.983+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:49:51.983+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:49:51.990+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'owners': 'airflow', 'last_parsed_time': datetime.datetime(2025, 3, 9, 13, 49, 51, 982552, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflo ... (839 characters truncated) ... d': None, 'dag_display_name': None, 'root_dag_id': None, 'scheduler_lock': None, 'dataset_expression': None, 'last_expired': None, 'pickle_id': None}]]
[2025-03-09T13:50:22.609+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:50:22.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:50:22.619+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:50:22.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:50:23.121+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:50:23.129+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:50:23.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:50:23.136+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:50:23.136+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:50:23.141+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:50:23.140+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:50:23.143+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'owners': 'airflow', 'last_parsed_time': datetime.datetime(2025, 3, 9, 13, 50, 23, 140571, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflo ... (839 characters truncated) ... d': None, 'dag_display_name': None, 'root_dag_id': None, 'scheduler_lock': None, 'dataset_expression': None, 'last_expired': None, 'pickle_id': None}]]
[2025-03-09T13:50:51.814+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:50:51.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:50:51.818+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:50:51.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:50:52.242+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:50:52.249+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:50:52.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:50:52.255+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:50:52.255+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:50:52.259+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:50:52.259+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:50:52.261+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'owners': 'airflow', 'last_parsed_time': datetime.datetime(2025, 3, 9, 13, 50, 52, 259280, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflo ... (839 characters truncated) ... d': None, 'dag_display_name': None, 'root_dag_id': None, 'scheduler_lock': None, 'dataset_expression': None, 'last_expired': None, 'pickle_id': None}]]
[2025-03-09T13:51:26.246+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:51:26.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:51:26.250+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:26.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:51:28.109+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:28.101+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 72, in <module>
    POSTGRES_JDBC_URL = Variable.get("POSTGRES_JDBC_URL")
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable POSTGRES_JDBC_URL does not exist'
[2025-03-09T13:51:28.113+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:51:28.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.888 seconds
[2025-03-09T13:51:58.610+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:51:58.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:51:58.616+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:58.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:51:59.103+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:51:59.194+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.193+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T13:51:59.205+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.205+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T13:51:59.209+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.209+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T13:51:59.214+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.213+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:51:59.215+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.215+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:51:59.220+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.219+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:51:59.221+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.221+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T13:51:59.222+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:51:59.228+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.228+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:51:59.234+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:51:59.234+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:51:59.236+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (839 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:52:29.853+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:52:29.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:52:29.856+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:52:29.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:52:30.197+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:52:30.210+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:52:30.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:52:30.230+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:52:30.230+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:52:30.236+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:52:30.236+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:52:30.240+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (839 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:53:01.094+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:53:01.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:53:01.099+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:53:01.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:53:01.787+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:53:01.798+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:53:01.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:53:01.806+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:53:01.805+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:53:01.829+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:53:01.829+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:53:01.833+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (838 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:53:32.455+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:53:32.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:53:32.461+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:53:32.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:53:33.042+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:53:33.058+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:53:33.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:53:33.070+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:53:33.070+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:53:33.077+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:53:33.077+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:53:33.084+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (838 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:54:03.726+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:54:03.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:54:03.731+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:54:03.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:54:04.280+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:54:04.305+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:54:04.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:54:04.313+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:54:04.313+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:54:04.318+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:54:04.318+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:54:04.322+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (838 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:54:34.984+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:54:34.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:54:34.991+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:54:34.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:54:35.548+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:54:35.556+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:54:35.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:54:35.562+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:54:35.562+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:54:35.569+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:54:35.569+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:54:35.573+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (839 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:55:06.257+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:55:06.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:55:06.263+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:55:06.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:55:06.757+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:55:06.774+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:55:06.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:55:06.784+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:55:06.784+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:55:06.788+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:55:06.788+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:55:06.791+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (838 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:55:37.622+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:55:37.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:55:37.631+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:55:37.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:55:37.961+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:55:37.971+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:55:37.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:55:37.981+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:55:37.981+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:55:37.988+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:55:37.987+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:55:37.991+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (839 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:56:08.785+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:56:08.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:56:08.790+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:56:08.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:56:09.143+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:56:09.155+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:56:09.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:56:09.312+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:56:09.312+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:56:09.317+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:56:09.317+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:56:09.320+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (838 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:56:39.548+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:56:39.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:56:39.553+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:56:39.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:56:40.054+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:56:40.063+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:56:40.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:56:40.069+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:56:40.069+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:56:40.074+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:56:40.074+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:56:40.076+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (838 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:57:10.777+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:57:10.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:57:10.783+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:57:10.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:57:11.393+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:57:11.401+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:57:11.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:57:11.407+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:57:11.407+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:57:11.417+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:57:11.417+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:57:11.423+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (839 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:57:42.143+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:57:42.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:57:42.147+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:57:42.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:57:42.657+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:57:42.667+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:57:42.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:57:42.679+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:57:42.679+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:57:42.688+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:57:42.688+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:57:42.696+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (839 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:58:13.657+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:58:13.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:58:13.665+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:13.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:58:14.012+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:58:14.023+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:14.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:58:14.031+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:14.030+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:58:14.035+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:14.035+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:58:14.038+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (838 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:58:44.887+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:58:44.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:58:44.898+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:44.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:58:45.270+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:58:45.285+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:45.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:58:45.303+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:45.303+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:58:45.308+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:45.308+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:58:45.311+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (839 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:58:54.687+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:58:54.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:58:54.691+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:54.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:58:55.028+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:58:55.211+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:55.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T13:58:55.218+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:55.218+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T13:58:55.222+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:58:55.222+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T13:58:55.224+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'description': 'ETL pipeline from PostgreSQL to ClickHouse for table daily_transaction_summary', 'fileloc': '/opt/airflow/dags/dag_daily_transaction ... (839 characters truncated) ... ': None, 'last_pickled': None, 'dag_display_name': None, 'dataset_expression': None, 'scheduler_lock': None, 'pickle_id': None, 'last_expired': None}]]
[2025-03-09T13:59:43.763+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:59:43.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T13:59:43.776+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:59:43.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:59:45.623+0000] {logging_mixin.py:190} INFO - [2025-03-09T13:59:45.614+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 384, in <module>
    AIRFLOW_PATH = Variable.get("LOCAL_AIRFLOW_PATH")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T13:59:45.624+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T13:59:45.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.876 seconds
[2025-03-09T14:00:16.128+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:00:16.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:00:16.134+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:00:16.654+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:00:16.772+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.772+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T14:00:16.776+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.776+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T14:00:16.779+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.779+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T14:00:16.781+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.781+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:00:16.785+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.785+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:00:16.795+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.795+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:00:16.801+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.801+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:00:16.801+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:00:16.809+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.809+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:00:16.815+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:16.815+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:00:16.818+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:00:47.486+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:00:47.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:00:47.489+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:47.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:00:47.805+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:00:47.821+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:47.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:00:47.829+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:47.828+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:00:47.833+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:00:47.833+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:00:47.836+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:01:18.653+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:01:18.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:01:18.657+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:01:18.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:01:19.311+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:01:19.326+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:01:19.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:01:19.333+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:01:19.333+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:01:19.341+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:01:19.341+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:01:19.353+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:01:49.984+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:01:49.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:01:49.987+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:01:49.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:01:50.495+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:01:50.511+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:01:50.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:01:50.518+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:01:50.518+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:01:50.523+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:01:50.523+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:01:50.526+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:02:21.163+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:02:21.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:02:21.167+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:02:21.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:02:21.692+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:02:21.703+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:02:21.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:02:21.713+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:02:21.713+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:02:21.718+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:02:21.718+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:02:21.721+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:02:52.416+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:02:52.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:02:52.420+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:02:52.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:02:52.986+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:02:52.994+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:02:52.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:02:53.001+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:02:53.001+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:02:53.007+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:02:53.007+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:02:53.010+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (836 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:03:23.760+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:03:23.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:03:23.769+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:03:23.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:03:24.285+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:03:24.301+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:03:24.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:03:24.310+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:03:24.310+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:03:24.315+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:03:24.314+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:03:24.317+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:03:55.151+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:03:55.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:03:55.159+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:03:55.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:03:55.507+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:03:55.518+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:03:55.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:03:55.526+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:03:55.526+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:03:55.531+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:03:55.531+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:03:55.533+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:04:26.291+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:04:26.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:04:26.299+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:04:26.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:04:26.618+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:04:26.630+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:04:26.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:04:26.859+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:04:26.858+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:04:26.864+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:04:26.864+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:04:26.866+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:04:57.186+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:04:57.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:04:57.193+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:04:57.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:04:57.738+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:04:57.746+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:04:57.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:04:57.752+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:04:57.752+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:04:57.756+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:04:57.756+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:04:57.758+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:05:28.472+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:05:28.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:05:28.479+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:05:28.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:05:28.962+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:05:28.972+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:05:28.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:05:28.978+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:05:28.978+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:05:28.983+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:05:28.982+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:05:28.985+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:05:59.768+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:05:59.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:05:59.774+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:05:59.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:06:00.190+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:06:00.199+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:06:00.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:06:00.207+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:06:00.207+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:06:00.212+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:06:00.212+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:06:00.214+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (837 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:06:31.153+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:06:31.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:06:31.164+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:06:31.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:06:31.514+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:06:31.524+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:06:31.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:06:31.532+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:06:31.532+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:06:31.537+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:06:31.537+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:06:31.540+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (838 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:07:02.331+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:07:02.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:07:02.338+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:02.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:07:02.673+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:07:02.684+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:02.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:07:02.694+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:02.694+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:07:02.699+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:02.699+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:07:02.702+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (837 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:07:33.546+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:07:33.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:07:33.555+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:33.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:07:33.883+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:07:34.045+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:34.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:07:34.051+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:34.051+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:07:34.055+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:34.055+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:07:34.057+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3425, in bulk_write_to_db
    dataset_manager.create_datasets(dataset_models=new_dataset_models, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/datasets/manager.py", line 65, in create_datasets
    session.flush()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1816, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1810, in _execute_context
    context = constructor(
              ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 1122, in _init_compiled
    key: processors[key](compiled_params[key])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/type_api.py", line 1673, in process
    return process_param(value, dialect)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/sqlalchemy.py", line 328, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
                                                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun': DateTime(2025, 3, 8, 0, 0, 0, tzinfo=Timezone('UTC')), 'processor_subdir': '/opt/airflow/dags', 'timetable_description': '', 'is_acti ... (837 characters truncated) ... ock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None, 'dag_display_name': None, 'dataset_expression': None, 'last_pickled': None}]]
[2025-03-09T14:07:51.523+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:07:51.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:07:51.525+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:51.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:07:51.535+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:07:51.534+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:07:51.535+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:07:51.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.039 seconds
[2025-03-09T14:08:21.675+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:08:21.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:08:21.679+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:08:21.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:08:21.685+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:08:21.683+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:08:21.685+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:08:21.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.032 seconds
[2025-03-09T14:08:52.016+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:08:52.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:08:52.019+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:08:52.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:08:52.025+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:08:52.024+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:08:52.026+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:08:52.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.034 seconds
[2025-03-09T14:09:22.988+0000] {processor.py:186} INFO - Started process (PID=153) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:09:22.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:09:22.992+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:09:22.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:09:22.999+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:09:22.997+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:09:22.999+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:09:23.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.036 seconds
[2025-03-09T14:09:53.904+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:09:53.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:09:53.931+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:09:53.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:09:53.942+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:09:53.941+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:09:53.942+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:09:53.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.063 seconds
[2025-03-09T14:10:24.061+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:10:24.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:10:24.065+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:10:24.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:10:24.071+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:10:24.069+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:10:24.071+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:10:24.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.034 seconds
[2025-03-09T14:10:54.295+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:10:54.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:10:54.298+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:10:54.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:10:54.304+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:10:54.302+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:10:54.304+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:10:54.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.032 seconds
[2025-03-09T14:11:24.477+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:11:24.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:11:24.480+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:11:24.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:11:24.485+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:11:24.484+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:11:24.486+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:11:24.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.030 seconds
[2025-03-09T14:11:54.549+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:11:54.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:11:54.553+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:11:54.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:11:54.558+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:11:54.557+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:11:54.558+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:11:54.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.034 seconds
[2025-03-09T14:12:15.405+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:12:15.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:12:15.408+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:12:15.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:12:15.418+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:12:15.417+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:12:15.418+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:12:15.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.039 seconds
[2025-03-09T14:12:45.542+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:12:45.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:12:45.544+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:12:45.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:12:45.549+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:12:45.547+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:12:45.549+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:12:45.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.031 seconds
[2025-03-09T14:13:16.140+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:13:16.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:13:16.150+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:13:16.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:13:16.156+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:13:16.155+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:13:16.157+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:13:16.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.048 seconds
[2025-03-09T14:13:47.323+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:13:47.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:13:47.328+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:13:47.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:13:47.335+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:13:47.334+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:13:47.335+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:13:47.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.039 seconds
[2025-03-09T14:13:51.920+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:13:51.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:13:51.923+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:13:51.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:13:51.933+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:13:51.932+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 2, in <module>
    from airflow.schedules.interval_schedule import schedule_daily
ModuleNotFoundError: No module named 'airflow.schedules'
[2025-03-09T14:13:51.933+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:13:51.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.034 seconds
[2025-03-09T14:14:20.989+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:14:20.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:14:20.993+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:14:20.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:14:21.002+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:14:21.001+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 387
    schedule_interval = 0 0 * * *,
                        ^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-03-09T14:14:21.003+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:14:21.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.031 seconds
[2025-03-09T14:14:26.282+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:14:26.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:14:26.286+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:14:26.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:14:26.337+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:14:26.337+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 6, in <module>
    from module.utilities import get_airflow_variables
ModuleNotFoundError: No module named 'module'
[2025-03-09T14:14:26.338+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:14:26.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.075 seconds
[2025-03-09T14:14:59.972+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:14:59.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:14:59.976+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:14:59.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:15:01.828+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:15:01.818+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: get_airflow_variables() takes 0 positional arguments but 1 was given
[2025-03-09T14:15:01.831+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:15:01.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.906 seconds
[2025-03-09T14:15:32.375+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:15:32.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:15:32.378+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:15:32.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:15:32.789+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:15:32.787+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: get_airflow_variables() takes 0 positional arguments but 1 was given
[2025-03-09T14:15:32.789+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:15:32.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.438 seconds
[2025-03-09T14:16:03.612+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:16:03.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:16:03.616+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:16:03.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:16:03.935+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:16:03.928+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: get_airflow_variables() takes 0 positional arguments but 1 was given
[2025-03-09T14:16:03.935+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:16:03.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.355 seconds
[2025-03-09T14:16:34.773+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:16:34.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:16:34.777+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:16:34.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:16:35.275+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:16:35.273+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: get_airflow_variables() takes 0 positional arguments but 1 was given
[2025-03-09T14:16:35.275+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:16:35.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.541 seconds
[2025-03-09T14:17:05.005+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:17:05.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:17:05.008+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:17:05.618+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:17:05.679+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.679+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T14:17:05.682+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.682+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T14:17:05.684+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.684+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T14:17:05.685+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.685+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:17:05.687+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.687+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:17:05.689+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.689+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:17:05.691+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.691+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:17:05.691+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:17:05.695+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.695+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:17:05.699+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:05.699+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:17:05.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.707 seconds
[2025-03-09T14:17:36.026+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:17:36.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:17:36.028+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:36.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:17:36.514+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:17:36.521+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:36.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:17:36.532+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:17:36.532+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:17:36.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.522 seconds
[2025-03-09T14:18:06.717+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:18:06.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:18:06.721+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:18:06.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:18:07.215+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:18:07.223+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:18:07.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:18:07.235+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:18:07.235+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:18:07.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.571 seconds
[2025-03-09T14:18:37.381+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:18:37.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:18:37.386+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:18:37.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:18:37.876+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:18:37.884+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:18:37.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:18:37.895+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:18:37.894+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:18:37.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.526 seconds
[2025-03-09T14:18:57.879+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:18:57.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:18:57.885+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:18:57.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:18:58.332+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:18:58.342+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:18:58.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:18:58.356+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:18:58.355+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:18:58.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.498 seconds
[2025-03-09T14:19:28.558+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:19:28.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:19:28.564+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:19:28.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:19:28.929+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:19:28.947+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:19:28.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:19:28.964+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:19:28.964+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:19:28.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.429 seconds
[2025-03-09T14:19:59.809+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:19:59.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:19:59.818+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:19:59.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:20:00.357+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:20:00.357+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:20:00.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:20:00.379+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:20:00.379+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:20:00.400+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:20:00.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:20:00.427+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:20:00.427+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:20:00.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.638 seconds
[2025-03-09T14:20:30.615+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:20:30.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:20:30.619+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:20:30.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:20:31.046+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:20:31.047+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:20:31.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:20:31.068+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:20:31.068+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:20:31.086+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:20:31.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:20:31.093+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:20:31.093+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:20:31.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.491 seconds
[2025-03-09T14:21:01.836+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:21:01.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:21:01.840+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:21:01.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:21:02.313+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:21:02.321+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:21:02.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:21:02.330+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:21:02.330+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:21:02.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.510 seconds
[2025-03-09T14:21:33.163+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:21:33.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:21:33.180+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:21:33.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:21:33.678+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:21:33.686+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:21:33.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:21:33.695+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:21:33.695+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:21:33.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.553 seconds
[2025-03-09T14:22:04.345+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:22:04.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:22:04.352+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:22:04.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:22:04.710+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:22:04.723+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:22:04.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:22:04.737+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:22:04.737+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:22:04.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.408 seconds
[2025-03-09T14:22:35.561+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:22:35.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:22:35.569+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:22:35.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:22:36.033+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:22:36.033+0000] {connectionpool.py:868} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=0, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff848e4bf0>: Failed to establish a new connection: [Errno 111] Connection refused')': /?
[2025-03-09T14:22:36.034+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:22:36.034+0000] {httpclient.py:459} WARNING - Unexpected Http Driver Exception
[2025-03-09T14:22:36.050+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:22:36.034+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1093, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1037, in send
    self.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff891d88c0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 449, in _raw_request
    response = self.http.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 871, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='clickhouse_db', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff891d88c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 33, in <module>
    ch_client = clickhouse_connect.get_client(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/__init__.py", line 122, in create_client
    return HttpClient(interface, host, port, username, password, database, access_token,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 161, in __init__
    super().__init__(database=database,
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 69, in __init__
    self._init_common_settings(apply_server_timezone)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 74, in _init_common_settings
    tuple(self.command('SELECT version(), timezone()', use_database=False))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 361, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 461, in _raw_request
    raise OperationalError(f'Error {ex} executing HTTP request attempt {attempts}{err_url}') from ex
clickhouse_connect.driver.exceptions.OperationalError: Error HTTPConnectionPool(host='clickhouse_db', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff891d88c0>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://clickhouse_db:8123)
[2025-03-09T14:22:36.052+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:22:36.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.516 seconds
[2025-03-09T14:23:04.132+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:23:04.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:23:04.138+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:04.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:23:05.996+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:05.991+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T14:23:05.997+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:23:06.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.893 seconds
[2025-03-09T14:23:36.513+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:23:36.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:23:36.517+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:36.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:23:37.098+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:23:37.197+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.197+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T14:23:37.201+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.201+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T14:23:37.205+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.205+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T14:23:37.208+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.208+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:23:37.214+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.214+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:23:37.219+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.218+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:23:37.221+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.221+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:23:37.221+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:23:37.230+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.230+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:23:37.238+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:23:37.238+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:23:37.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.743 seconds
[2025-03-09T14:24:07.786+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:24:07.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:24:07.790+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:07.790+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:24:08.234+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:24:08.235+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:08.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:24:08.254+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:08.254+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:24:08.274+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:08.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:24:08.513+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:08.513+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:24:08.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.764 seconds
[2025-03-09T14:24:39.023+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:24:39.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:24:39.027+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:39.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:24:39.373+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:24:39.374+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:39.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:24:39.396+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:39.396+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:24:39.626+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:39.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:24:39.637+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:24:39.637+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:24:39.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.664 seconds
[2025-03-09T14:25:10.417+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:25:10.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:25:10.429+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:10.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:25:11.008+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:25:11.010+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:11.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:25:11.081+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:11.080+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:25:11.116+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:11.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:25:11.124+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:11.124+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:25:11.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.729 seconds
[2025-03-09T14:25:41.669+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:25:41.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:25:41.683+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:41.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:25:42.260+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:25:42.260+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:42.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:25:42.286+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:42.286+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:25:42.308+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:42.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:25:42.320+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:25:42.320+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:25:42.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.697 seconds
[2025-03-09T14:27:14.189+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:27:14.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:27:14.192+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:14.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:27:15.902+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:15.895+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T14:27:15.903+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:27:15.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.731 seconds
[2025-03-09T14:27:46.430+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:27:46.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:27:46.431+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:46.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:27:47.080+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:27:47.252+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.251+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T14:27:47.258+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.258+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T14:27:47.260+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.260+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T14:27:47.263+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.263+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:27:47.267+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.266+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:27:47.268+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.268+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:27:47.270+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.270+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:27:47.270+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:27:47.278+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.278+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:27:47.288+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:27:47.287+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:27:47.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.875 seconds
[2025-03-09T14:28:17.920+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:28:17.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:28:17.922+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:28:17.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:28:18.263+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:28:18.274+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:28:18.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:28:18.303+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:28:18.302+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:28:18.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.408 seconds
[2025-03-09T14:28:49.057+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:28:49.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:28:49.060+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:28:49.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:28:49.545+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:28:49.553+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:28:49.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:28:49.565+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:28:49.565+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:28:49.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.562 seconds
[2025-03-09T14:29:20.246+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:29:20.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:29:20.252+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:29:20.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:29:20.802+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:29:20.814+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:29:20.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:29:20.823+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:29:20.823+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:29:20.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.636 seconds
[2025-03-09T14:29:51.611+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:29:51.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:29:51.615+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:29:51.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:29:52.215+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:29:52.217+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:29:52.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:29:52.261+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:29:52.261+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:29:52.290+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:29:52.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:29:52.311+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:29:52.311+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:29:52.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.730 seconds
[2025-03-09T14:30:22.441+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:30:22.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:30:22.448+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:30:22.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:30:23.122+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:30:23.123+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:30:23.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:30:23.179+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:30:23.178+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:30:23.226+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:30:23.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:30:23.243+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:30:23.243+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:30:23.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.860 seconds
[2025-03-09T14:30:53.851+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:30:53.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:30:53.855+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:30:53.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:30:54.380+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:30:54.391+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:30:54.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:30:54.405+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:30:54.405+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:30:54.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.569 seconds
[2025-03-09T14:31:25.292+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:31:25.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:31:25.304+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:31:25.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:31:25.741+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:31:25.756+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:31:25.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:31:25.769+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:31:25.769+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:31:25.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.500 seconds
[2025-03-09T14:31:56.595+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:31:56.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:31:56.605+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:31:56.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:31:57.008+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:31:57.024+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:31:57.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:31:57.050+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:31:57.050+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:31:57.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.488 seconds
[2025-03-09T14:32:27.424+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:32:27.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:32:27.435+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:32:27.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:32:28.089+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:32:28.101+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:32:28.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:32:28.119+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:32:28.118+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:32:28.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.740 seconds
[2025-03-09T14:33:26.339+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:33:26.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:33:26.344+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:26.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:33:28.306+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:28.278+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T14:33:28.308+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:33:28.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.991 seconds
[2025-03-09T14:33:58.770+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:33:58.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:33:58.773+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:58.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:33:59.316+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:33:59.423+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.422+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T14:33:59.433+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.433+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T14:33:59.436+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.436+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T14:33:59.440+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.440+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:33:59.447+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.447+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:33:59.453+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.453+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:33:59.459+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.459+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:33:59.459+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:33:59.465+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.465+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:33:59.471+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:33:59.471+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:33:59.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.715 seconds
[2025-03-09T14:34:29.996+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:34:29.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:34:30.001+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:34:30.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:34:30.354+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:34:30.368+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:34:30.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:34:30.382+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:34:30.382+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:34:30.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.405 seconds
[2025-03-09T14:39:00.830+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:39:00.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:39:00.834+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:39:00.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:39:01.330+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:39:01.343+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:39:01.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:39:01.357+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:39:01.357+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:39:01.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.549 seconds
[2025-03-09T14:39:31.640+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:39:31.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:39:31.642+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:39:31.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:39:32.117+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:39:32.118+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:39:32.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:39:32.141+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:39:32.141+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:39:32.155+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:39:32.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:39:32.161+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:39:32.161+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:39:32.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.534 seconds
[2025-03-09T14:42:47.273+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:42:47.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:42:47.277+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:42:47.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:42:49.300+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:42:49.293+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T14:42:49.301+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:42:49.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 2.047 seconds
[2025-03-09T14:43:19.779+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:43:19.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:43:19.783+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:19.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:43:20.336+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:43:20.422+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.422+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T14:43:20.428+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.428+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T14:43:20.431+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.431+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T14:43:20.434+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.434+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:43:20.439+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.439+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:43:20.443+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.443+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:43:20.445+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.445+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:43:20.445+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:43:20.452+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.452+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:43:20.460+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:20.460+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:43:20.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.694 seconds
[2025-03-09T14:43:51.057+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:43:51.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:43:51.068+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:51.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:43:51.571+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:43:51.586+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:51.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:43:51.608+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:43:51.608+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:43:51.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.629 seconds
[2025-03-09T14:44:22.440+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:44:22.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:44:22.446+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:44:22.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:44:23.184+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:44:23.197+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:44:23.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:44:23.222+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:44:23.222+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:44:23.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.819 seconds
[2025-03-09T14:45:54.019+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:45:54.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:45:54.022+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:45:54.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:45:55.545+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:45:55.542+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T14:45:55.546+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:45:55.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.537 seconds
[2025-03-09T14:46:17.407+0000] {processor.py:186} INFO - Started process (PID=15) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:46:17.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:46:17.410+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:17.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:46:19.302+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:19.279+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T14:46:19.304+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:46:19.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.932 seconds
[2025-03-09T14:46:49.895+0000] {processor.py:186} INFO - Started process (PID=26) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:46:49.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:46:49.898+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:49.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:46:50.463+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:46:50.581+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.581+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T14:46:50.588+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.588+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T14:46:50.600+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.599+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T14:46:50.606+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.606+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:46:50.608+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.608+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:46:50.610+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.610+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:46:50.614+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.614+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:46:50.614+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:46:50.623+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.623+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:46:50.630+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:46:50.630+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:46:50.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.755 seconds
[2025-03-09T14:47:21.366+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:47:21.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:47:21.374+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:47:21.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:47:22.095+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:47:22.110+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:47:22.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:47:22.133+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:47:22.133+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:47:22.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.789 seconds
[2025-03-09T14:47:52.944+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:47:52.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:47:52.955+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:47:52.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:47:53.585+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:47:53.598+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:47:53.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:47:53.613+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:47:53.613+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:47:53.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.712 seconds
[2025-03-09T14:48:25.789+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:48:25.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:48:25.796+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:25.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:48:27.881+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:27.874+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T14:48:27.882+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:48:27.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 2.112 seconds
[2025-03-09T14:48:58.398+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:48:58.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:48:58.401+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:58.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:48:58.940+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:48:59.047+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.047+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T14:48:59.060+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.060+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T14:48:59.064+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.063+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T14:48:59.066+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.066+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:48:59.068+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.068+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:48:59.070+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.070+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:48:59.072+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.072+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:48:59.076+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:48:59.082+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.082+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:48:59.089+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:48:59.089+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:48:59.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.712 seconds
[2025-03-09T14:49:29.653+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:49:29.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:49:29.657+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:49:29.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:49:30.048+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:49:30.061+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:49:30.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:49:30.081+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:49:30.081+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:49:30.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.465 seconds
[2025-03-09T14:52:00.271+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:52:00.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:52:00.275+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:00.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:52:01.892+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:01.885+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T14:52:01.893+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:52:01.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.643 seconds
[2025-03-09T14:52:32.431+0000] {processor.py:186} INFO - Started process (PID=27) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:52:32.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:52:32.436+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:32.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:52:33.028+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:52:33.143+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.143+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T14:52:33.150+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.150+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T14:52:33.153+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.153+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T14:52:33.155+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.155+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:52:33.159+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.159+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:52:33.164+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.164+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:52:33.166+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.166+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T14:52:33.166+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:52:33.174+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.174+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T14:52:33.182+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:52:33.182+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:52:33.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.767 seconds
[2025-03-09T14:53:03.699+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:53:03.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:53:03.704+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:53:03.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:53:04.040+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:53:04.048+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:53:04.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:53:04.059+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:53:04.059+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:53:04.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.379 seconds
[2025-03-09T14:53:34.814+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:53:34.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:53:34.818+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:53:34.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:53:35.376+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:53:35.383+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:53:35.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:53:35.392+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:53:35.392+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:53:35.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.599 seconds
[2025-03-09T14:54:06.011+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:54:06.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:54:06.019+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:54:06.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:54:06.586+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:54:06.594+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:54:06.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:54:06.604+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:54:06.603+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:54:06.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.606 seconds
[2025-03-09T14:54:37.238+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:54:37.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:54:37.243+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:54:37.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:54:37.739+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:54:37.748+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:54:37.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:54:37.760+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:54:37.760+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:54:37.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.539 seconds
[2025-03-09T14:55:08.349+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:55:08.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:55:08.356+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:55:08.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:55:08.855+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:55:08.864+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:55:08.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:55:08.874+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:55:08.874+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:55:08.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.551 seconds
[2025-03-09T14:55:39.553+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:55:39.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:55:39.563+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:55:39.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:55:40.083+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:55:40.106+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:55:40.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:55:40.120+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:55:40.120+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T14:55:40.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.599 seconds
[2025-03-09T14:56:10.851+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:56:10.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:56:10.860+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:56:10.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:56:11.308+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:56:11.309+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:56:11.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:56:11.333+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:56:11.333+0000] {processor.py:457} INFO - Running SLA Checks for dag_daily_transaction_summary
[2025-03-09T14:56:11.394+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:56:11.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:56:11.413+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:56:11.413+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:56:11.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.601 seconds
[2025-03-09T14:56:42.083+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:56:42.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:56:42.091+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:56:42.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:56:42.475+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:56:42.488+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:56:42.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:56:42.726+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:56:42.725+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:56:42.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.666 seconds
[2025-03-09T14:57:13.125+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:57:13.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:57:13.133+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:57:13.132+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:57:13.694+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:57:13.706+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:57:13.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:57:13.721+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:57:13.721+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:57:13.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.642 seconds
[2025-03-09T14:57:44.473+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:57:44.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:57:44.494+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:57:44.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:57:45.047+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:57:45.070+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:57:45.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:57:45.089+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:57:45.089+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:57:45.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.646 seconds
[2025-03-09T14:58:15.801+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:58:15.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:58:15.808+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:58:15.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:58:16.366+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:58:16.379+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:58:16.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:58:16.394+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:58:16.394+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:58:16.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.626 seconds
[2025-03-09T14:58:47.055+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:58:47.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:58:47.064+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:58:47.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:58:47.535+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:58:47.548+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:58:47.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:58:47.558+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:58:47.558+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:58:47.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.533 seconds
[2025-03-09T14:59:18.364+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:59:18.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:59:18.369+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:59:18.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:59:18.722+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:59:18.747+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:59:18.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:59:18.760+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:59:18.760+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:59:18.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.413 seconds
[2025-03-09T14:59:49.653+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:59:49.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T14:59:49.662+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:59:49.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:59:50.052+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T14:59:50.062+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:59:50.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T14:59:50.076+0000] {logging_mixin.py:190} INFO - [2025-03-09T14:59:50.076+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-09 00:00:00+00:00, run_after=2025-03-10 00:00:00+00:00
[2025-03-09T14:59:50.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.462 seconds
[2025-03-09T15:00:52.698+0000] {processor.py:186} INFO - Started process (PID=17) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:00:52.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:00:52.706+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:00:52.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:00:54.705+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:00:54.694+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T15:00:54.707+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:00:54.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 2.026 seconds
[2025-03-09T15:01:25.310+0000] {processor.py:186} INFO - Started process (PID=29) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:01:25.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:01:25.317+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:01:25.843+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:01:25.939+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.939+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T15:01:25.951+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.951+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T15:01:25.954+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.954+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T15:01:25.956+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.956+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:01:25.957+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.957+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:01:25.959+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.959+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:01:25.961+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.961+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:01:25.961+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.961+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:01:25.966+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.966+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T15:01:25.973+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:25.973+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:01:25.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.679 seconds
[2025-03-09T15:01:56.614+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:01:56.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:01:56.624+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:56.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:01:56.967+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:01:56.981+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:56.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:01:56.995+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:01:56.994+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:01:57.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.410 seconds
[2025-03-09T15:02:27.886+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:02:27.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:02:27.894+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:02:27.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:02:28.296+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:02:28.316+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:02:28.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:02:28.537+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:02:28.537+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:02:28.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.705 seconds
[2025-03-09T15:02:59.220+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:02:59.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:02:59.227+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:02:59.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:02:59.918+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:02:59.946+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:02:59.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:02:59.965+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:02:59.965+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:03:00.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.794 seconds
[2025-03-09T15:03:30.644+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:03:30.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:03:30.653+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:03:30.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:03:31.109+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:03:31.117+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:03:31.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:03:31.129+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:03:31.129+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:03:31.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.497 seconds
[2025-03-09T15:04:01.798+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:04:01.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:04:01.801+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:04:01.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:04:02.261+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:04:02.271+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:04:02.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:04:02.282+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:04:02.282+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:04:02.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.497 seconds
[2025-03-09T15:04:33.013+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:04:33.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:04:33.019+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:04:33.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:04:33.508+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:04:33.519+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:04:33.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:04:33.531+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:04:33.531+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:04:33.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.537 seconds
[2025-03-09T15:05:04.301+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:05:04.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:05:04.318+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:05:04.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:05:04.796+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:05:04.804+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:05:04.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:05:04.816+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:05:04.816+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:05:04.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.551 seconds
[2025-03-09T15:05:35.704+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:05:35.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:05:35.714+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:05:35.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:05:36.064+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:05:36.074+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:05:36.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:05:36.087+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:05:36.087+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:05:36.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.400 seconds
[2025-03-09T15:06:06.511+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:06:06.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:06:06.519+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:06:06.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:06:06.980+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:06:06.992+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:06:06.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:06:07.264+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:06:07.264+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:06:07.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.786 seconds
[2025-03-09T15:06:38.152+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:06:38.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:06:38.158+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:06:38.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:06:38.820+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:06:38.829+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:06:38.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:06:38.838+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:06:38.838+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:06:38.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.705 seconds
[2025-03-09T15:08:04.586+0000] {processor.py:186} INFO - Started process (PID=16) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:08:04.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:08:04.591+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:04.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:08:06.285+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:06.281+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T15:08:06.286+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:08:06.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.717 seconds
[2025-03-09T15:08:37.155+0000] {processor.py:186} INFO - Started process (PID=28) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:08:37.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:08:37.166+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:08:37.682+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:08:37.794+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.794+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T15:08:37.806+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.805+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T15:08:37.809+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.808+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T15:08:37.814+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.813+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:08:37.815+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.815+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:08:37.817+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.817+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:08:37.819+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.819+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:08:37.819+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:08:37.825+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.825+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T15:08:37.831+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:08:37.831+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:08:37.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.692 seconds
[2025-03-09T15:09:08.616+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:09:08.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:09:08.623+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:09:08.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:09:09.062+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:09:09.074+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:09:09.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:09:09.105+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:09:09.105+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:09:09.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.532 seconds
[2025-03-09T15:09:39.934+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:09:39.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:09:39.937+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:09:39.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:09:40.299+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:09:40.307+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:09:40.307+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:09:40.528+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:09:40.528+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:09:40.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.652 seconds
[2025-03-09T15:10:11.223+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:10:11.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:10:11.228+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:10:11.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:10:11.677+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:10:11.684+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:10:11.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:10:11.695+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:10:11.694+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:10:11.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.496 seconds
[2025-03-09T15:10:42.395+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:10:42.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:10:42.400+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:10:42.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:10:42.901+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:10:42.909+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:10:42.908+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:10:42.918+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:10:42.918+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:10:42.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.558 seconds
[2025-03-09T15:11:13.696+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:11:13.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:11:13.702+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:11:13.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:11:14.328+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:11:14.345+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:11:14.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:11:14.358+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:11:14.358+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:11:14.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.740 seconds
[2025-03-09T15:11:45.165+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:11:45.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:11:45.173+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:11:45.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:11:45.727+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:11:45.739+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:11:45.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:11:45.754+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:11:45.754+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:11:45.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.625 seconds
[2025-03-09T15:12:16.557+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:12:16.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:12:16.565+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:12:16.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:12:17.109+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:12:17.117+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:12:17.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:12:17.126+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:12:17.126+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:12:17.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.599 seconds
[2025-03-09T15:12:48.150+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:12:48.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:12:48.166+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:12:48.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:12:48.533+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:12:48.544+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:12:48.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:12:48.558+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:12:48.557+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:12:48.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.431 seconds
[2025-03-09T15:13:19.037+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:13:19.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:13:19.047+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:13:19.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:13:19.459+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:13:19.474+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:13:19.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:13:19.805+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:13:19.805+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:13:19.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.820 seconds
[2025-03-09T15:13:50.523+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:13:50.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:13:50.530+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:13:50.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:13:51.078+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:13:51.088+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:13:51.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:13:51.101+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:13:51.101+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:13:51.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.618 seconds
[2025-03-09T15:14:21.828+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:14:21.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:14:21.834+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:14:21.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:14:22.346+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:14:22.354+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:14:22.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:14:22.367+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:14:22.367+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:14:22.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.559 seconds
[2025-03-09T15:14:53.100+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:14:53.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:14:53.108+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:14:53.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:14:53.694+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:14:53.705+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:14:53.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:14:53.718+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:14:53.718+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:14:53.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.649 seconds
[2025-03-09T15:15:24.512+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:15:24.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:15:24.526+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:15:24.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:15:25.019+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:15:25.027+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:15:25.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:15:25.041+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:15:25.041+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:15:25.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.554 seconds
[2025-03-09T15:15:56.075+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:15:56.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:15:56.082+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:15:56.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:15:56.585+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:15:56.598+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:15:56.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:15:56.613+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:15:56.613+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:15:56.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.577 seconds
[2025-03-09T15:16:27.496+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:16:27.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:16:27.503+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:16:27.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:16:27.900+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:16:27.910+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:16:27.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:16:27.924+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:16:27.923+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:16:27.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.446 seconds
[2025-03-09T15:16:58.813+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:16:58.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:16:58.829+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:16:58.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:16:59.216+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:16:59.709+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:16:59.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:16:59.729+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:16:59.729+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:16:59.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.944 seconds
[2025-03-09T15:17:30.550+0000] {processor.py:186} INFO - Started process (PID=164) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:17:30.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:17:30.558+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:17:30.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:17:31.122+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:17:31.130+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:17:31.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:17:31.143+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:17:31.143+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:17:31.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.628 seconds
[2025-03-09T15:18:02.098+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:18:02.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:18:02.111+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:18:02.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:18:02.716+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:18:02.723+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:18:02.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:18:02.735+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:18:02.735+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:18:02.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.659 seconds
[2025-03-09T15:18:33.122+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:18:33.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:18:33.129+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:18:33.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:18:33.612+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:18:33.623+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:18:33.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:18:33.635+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:18:33.635+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:18:33.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.548 seconds
[2025-03-09T15:20:57.415+0000] {processor.py:186} INFO - Started process (PID=17) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:20:57.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:20:57.423+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:20:57.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:20:59.294+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:20:59.286+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dag_daily_transaction_summary.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_daily_transaction_summary.py", line 34, in <module>
    host = get_airflow_variables("CLICKHOUSE_CONN"),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/module/utilities.py", line 5, in get_airflow_variables
    "AIRFLOW_PATH" : Variable.get("LOCAL_AIRFLOW_PATH"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable LOCAL_AIRFLOW_PATH does not exist'
[2025-03-09T15:20:59.296+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:20:59.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 1.900 seconds
[2025-03-09T15:21:30.041+0000] {processor.py:186} INFO - Started process (PID=29) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:21:30.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:21:30.047+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:21:30.576+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:21:30.648+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.648+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:dag_daily_transaction_summary
[2025-03-09T15:21:30.654+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.654+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:dag_daily_transaction_summary
[2025-03-09T15:21:30.660+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.660+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:dag_daily_transaction_summary
[2025-03-09T15:21:30.674+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.674+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:21:30.682+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.682+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:21:30.693+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.693+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:21:30.698+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.698+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:dag_daily_transaction_summary
[2025-03-09T15:21:30.699+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:21:30.705+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.704+0000] {dag.py:3262} INFO - Creating ORM DAG for dag_daily_transaction_summary
[2025-03-09T15:21:30.710+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:21:30.709+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:21:30.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.688 seconds
[2025-03-09T15:22:01.342+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:22:01.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:22:01.383+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:22:01.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:22:01.732+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:22:01.741+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:22:01.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:22:01.761+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:22:01.761+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:22:01.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.443 seconds
[2025-03-09T15:22:32.523+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:22:32.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dag_daily_transaction_summary.py for tasks to queue
[2025-03-09T15:22:32.528+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:22:32.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:22:32.863+0000] {processor.py:925} INFO - DAG(s) 'dag_daily_transaction_summary' retrieved from /opt/airflow/dags/dag_daily_transaction_summary.py
[2025-03-09T15:22:32.872+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:22:32.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T15:22:33.117+0000] {logging_mixin.py:190} INFO - [2025-03-09T15:22:33.117+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_daily_transaction_summary to 2025-03-08 00:00:00+00:00, run_after=2025-03-09 00:00:00+00:00
[2025-03-09T15:22:33.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dag_daily_transaction_summary.py took 0.646 seconds
